---
title: "class09_mini_project"
author: 'Hope (PID: A15652616)'
date: "10/26/2021"
output:
  pdf_document: default
  html_document: default
---

Import data
```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
```

We don't want to include the analysis given in the file
```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
```


setup a separate new vector called diagnosis that contains the data from the diagnosis column of the original dataset. We will store this as a factor (useful for plotting) and use this later to check our results.
```{r}
# Create diagnosis vector for later
diagnosis <- as.factor(c(wisc.df[,1]) )
```


# Q1. How many observations are in this dataset?
```{r}
dim(wisc.data)
```
There are 569 patients with 30 different measurements

# Q2. How many of the observations have a malignant diagnosis?
```{r}
table(diagnosis)
```
There were 212 people with a malignant diagnosis.

# Q3. How many variables/features in the data are suffixed with _mean?
```{r}
?grep
colnames(wisc.df)
length(grep("mean", colnames(wisc.df)))
```
There are 10 variables/features with the suffix "mean"


The next step in your analysis is to perform principal component analysis (PCA) on wisc.data.

Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the colMeans() and apply() functions like you’ve done before.
```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```


Execute PCA with the prcomp() function on the wisc.data, scaling if appropriate, and assign the output model to wisc.pr.
```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale. = TRUE)
```

Summarize
```{r}
# Look at summary of results
summary(wisc.pr)
```

# Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
There is 44% of the original variance captured by PC1.

# Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
You need 3 principal components to describe at least 70% of the original variance in the data.

# Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
You need 7 principal components to describe at least 90% of the original variance in the data.

Look at biplot
```{r}
biplot(wisc.pr)
```
# Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
This plot is difficult to understand and everything is too close to be able to actually read.

We can separate this out a little better. 


Let's make a score plot
```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[, 1:2 ], col = as.factor(diagnosis))
```


# Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
```{r}
plot(wisc.pr$x[, c(1,3) ], col = as.factor(diagnosis), 
     xlab = "PC1", ylab = "PC3")
```
These graphs make it much easier to compare different principal components compared to the biplot seen before. We can see that PC1 explains the most variance compared to both PC2 and PC3. Overall we see there is a bunching of malignant vs benign samples.


We can also graph this using ggplot to make it look a little better.

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=as.factor(diagnosis)) + 
  geom_point()
```


We now want to explain the variance 

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

Calculate the variance explained by each principal component by dividing by the total variance explained of all principal components. Assign this to a variable called pve and create a plot of variance explained for each principal component.
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```


Look at a scree plot
```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

# Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
```{r}
wisc.pr$rotation["concave.points_mean",1]
```


# Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
```{r}
summary(wisc.pr)
```
You need 5 PC's to explain 80% of the variance 


## Let's start looking at hierarchical clustering

Scale the wisc.data data using the “scale()” function

```{r}
data.scaled <- scale(wisc.data)
```

Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset and assign the result to data.dist.
```{r}
data.dist <- dist(data.scaled)
```

Create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.
```{r}
wisc.hclust <- hclust(data.dist)
```

# Results of hierarchical clustering

Let’s use the hierarchical clustering model you just created to determine a height (or distance between clusters) where a certain number of clusters exists.

## Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
```
The height is 21

# Selecting number of clusters

This exercise will help you determine if, in this case, hierarchical clustering provides a promising new feature.

Use cutree() to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```

We can use the table() function to compare the cluster membership to the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
```

## Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

The best cluster match is 2. 


## Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
wisc.pc.hclust <- hclust(dist(wisc.pr$x[,1:3]),
                         method="ward.D2")
```

```{r}
 wisc.pc.hclust <- hclust(dist(wisc.pr$x[,1:3]),
                         method="single")
```
ward.d2 was the best method because there was a logical flow to the clustering that was easier for me to understand.


# Clustering on PCA results

In this final section, you will put together several steps you used earlier and, in doing so, you will experience some of the creativity and open endedness that is typical in unsupervised learning.

```{r}
 grps <- cutree(wisc.pc.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

## Q15. How well does the newly created model with four clusters separate out the two diagnoses?

It separates the two diagnoses out well. 

## Compare to actual diagnoses

```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```

# Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
table(diagnosis)
```
The k-means and hierarchical clustering models separate the diagnosis very well. This resulted in the exact same results that the original data concluded.


# Sensitivity/Specificity

## Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Sensitivity: TP/(TP+FN)

```{r}
179/(179+33)
```

Specificity: TN/(TN+FN)

```{r}
333/(333+24)
```


# Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")

```

## Q18. Which of these new patients should we prioritize for follow up based on your results?

Patient 2 should be prioritized based on these results. 


